{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ability to give a gift to a friend on instagram\n",
    "# ability to create tweets-like feature on instagram\n",
    "# create a marketplace for educators to sell their courses on instagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain, ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.langchain import WandbTracer\n",
    "from serpapi import GoogleSearch\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from http.client import responses as http_responses\n",
    "import os, sys, datetime\n",
    "\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_template = \"\"\"\\\n",
    "You are a tech product manager. You have to help the user create a Product Requirement Document based on the questions the user asks you. The user will ask you specific questions about each topic they want to be included in the PRD. \n",
    "\n",
    "Do not repeat the same information again and again. Answers to each question should be unique and not repetitive. By this I mean do not repeat any ideas or sentences. Do not copy statements and ideas from previous sections. Any ideas or examples should only be in accordance to the particular section.\n",
    "\n",
    "Format your responses in Markdown mode with each topic being the ##Heading, and your answer being the content. Highlight important points in **bold**. Give the PRD a suitable #Title.\n",
    "\n",
    "For reference, let us say there are 3 people - A, B, and C belonging to different age groups, professions, and geographies. A is a 20-year-old college student from India. B is a 40-year-old working professional from the US. C is a 60-year-old retired person from the UK.\n",
    "If required, for that particular section, you can use any of these people as examples to explain your point. The user does not know anything about these people.\n",
    "\n",
    "You do not need to include these 3 people in every section. You can use them as examples only if required. You can also use other examples if you want to. You can also use yourself as an example if you want to.\n",
    "\n",
    "Current conversation:\n",
    "{history}\n",
    "Human: {input}\n",
    "AI: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=string_template,\n",
    "    input_variables=[\"history\", \"input\"],\n",
    ")\n",
    "\n",
    "prompts_list = [\n",
    "    \"\"\"Product Overview:\n",
    "Define the Purpose and Scope of this product. It should include how different groups of users across ages, genders, and geographies can use this product. Include an overview of the product. Why should one use this product? Define the target audience and stakeholders in detail. Also, include the rationale behind having the particular group as the target audience. Explain the gap it is trying to fill as well - how it is different from and better than other similar products?\"\"\",\n",
    "    \"\"\"Product Objectives:\n",
    "First, analyze whether the product objectives align with the company objectives if the company and company objectives are mentioned. Else, talk about the objectives of the product, what it will help achieve, and how it will assist customers. Think aloud. Explain your reasoning. Also, talk about why and how the business models of the product and company match. What company goals can the product help achieve - be it attracting customers, generating profits, or promoting the goodwill of the company? Also, explain how it would do this.\"\"\",\n",
    "#     \"\"\"Market Research:\n",
    "# First, list out current and potential competitors. Current competitors should include already established businesses/products. Potential competitors should include products and businesses that aren’t yet popular or are still under development/ beta version. Also include major or minor differences between our product and the competitor products you have identified. Analyze how aspects of our product or competitor products are better for that particular aspect. How do the target customers different? Does our product better cater to current trends and expectations of the users? How? What should the product include to meet those trends and expectations.\"\"\",\n",
    "#     \"\"\"Competitive Analysis Table:\n",
    "# Use all the above competitors to create a competitive analysis of these applications in a tabular form using the following points - user base, user region, different features supported, and pricing tiers. Don't limit yourself to these categories and think of other categories yourself. Return the output in a well-structured Markdown table\"\"\",\n",
    "    \"\"\"Feature Requirements:\n",
    "What are some of the important features that should be implemented? Follow the MoSCoW format (Must have, Should have, Could have, Won’t have, along with why). How are we going to collect user inputs and use user data that we collect to make the product better and add other features?\"\"\",\n",
    "    \"\"\"Launch Strategy:\n",
    "Compare US vs International markets for this product. Also, analyze this product and figure out what customer demographic is this product for. Based on these things, come up with a detailed launch strategy for the product. List the TAM vs SAM vs SOM. TAM or Total Available Market is the total market demand for a product or service. SAM or Serviceable Available Market is the segment of the TAM targeted by your products and services which is within your geographical reach. SOM or Serviceable Obtainable Market is the portion of SAM that you can capture.\"\"\",\n",
    "    \"\"\"User Stories:\n",
    "Create user stories for the product. User stories are short, simple descriptions of a feature told from the perspective of the person who desires the new capability, usually a user or customer of the system. They typically follow a simple template: As a < type of user >, I want < some goal > so that < some reason >. For example, As a college student, I want to be able to share my notes with my friends so that I can help them with their studies.\"\"\",\n",
    "    \"\"\"Acceptance Criteria:\n",
    "Define the quality of completeness required to be able to get to the MVP stage of this product.\"\"\",\n",
    "    \"\"\"Success Metrics:\n",
    "How do we define success in this product? What are the KPIs to look out for? How are they measured? Why do those KPIs matter? How are we going to use these KPIs to make the product better?\"\"\",\n",
    "    \"\"\"Technical Feasibilities:\n",
    "Outline the technical roadmap for this product. What mobile devices should this application be available for? What is a scalable and reliable tech stack which can be used for the frontend and the backend for this application?\"\"\",\n",
    "    \"\"\"Timeline:\n",
    "Define the timeline for the product development. In addition to the timeline, what are the resources required to complete this project. Think about the resources required for each stage of the project, the number of employees required for each stage, and the time required for each stage.\"\"\"\n",
    "]\n",
    "\n",
    "product_names = [\"DateSmart\", \"TalentScout\", \"MusicMate\"]\n",
    "product_descriptions = [\n",
    "    \"A dating app that encourages users to have a conversation with each other before deciding whether they want to match. While some dating apps allow direct messages, it is only for plus users, and only to a limited number of people. Our app’s focus is to encourage conversation first. The app ensures strict verification to prevent fraud, scamsters and fake accounts.\",\n",
    "    \"A Sports Analytics based product that allows coaches, analysts, team managers and owners scout for talent based on performances in the domestic and lower division circuits. The app will take lower division statistics, team information, team-mates’ information of players, along with ground information and weather information on match days, to predict how a player will fare in higher level of sports (national and international). State-of-the-art models such as Graph Neural Networks will be used to generate highly accurate predictions.\",\n",
    "    \"An app that recommends music to you based on your preferences, time of the day, and what activity you did before, and what you plan to do after. The app will use predictive modelling, frequency modelling, and NLP techniques. The app will also have a social media aspect to it, where you can share your music with your friends, and see what they are listening to.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product name: DateSmart\n",
      "Total tokens used: 27370\n",
      "Prompt Tokens: 23597\n",
      "Completion Tokens: 3773\n",
      "Successful Requests: 10\n",
      "Total cost to generate: $0.93\n"
     ]
    }
   ],
   "source": [
    "for product_name, product_description in zip(product_names[0:1], product_descriptions[0:1]):\n",
    "\n",
    "    chat = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    )\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"chat-prd-gpt-4\",\n",
    "        config={\n",
    "            \"model\": \"gpt-4\",\n",
    "            \"temperature\": 0\n",
    "        },\n",
    "        entity=\"arihantsheth\",\n",
    "        name=f\"{product_name}_gpt-4\",\n",
    "    )\n",
    "\n",
    "    memory = ConversationBufferMemory()\n",
    "\n",
    "    chain = LLMChain(\n",
    "        llm=chat,\n",
    "        memory=memory,\n",
    "        prompt=prompt_template,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    with get_openai_callback() as callback:\n",
    "\n",
    "        initial_output = chain.predict(\n",
    "            input=f\"\"\"\\\n",
    "I want to create the following new product:\n",
    "{product_name}.\n",
    "\n",
    "Product description: {product_description}\n",
    "\n",
    "DO NOT START WRITING. WAIT FOR THE HUMAN TO WRITE \"Start generating the PRD\" BEFORE YOU START WRITING.\n",
    "\"\"\", \n",
    "            callbacks=[WandbTracer()]\n",
    ")\n",
    "\n",
    "        output = \"\"\n",
    "        for i, prompt in enumerate(prompts_list):\n",
    "\n",
    "            # with get_openai_callback() as callback:\n",
    "\n",
    "            output += chain.predict(\n",
    "                input=prompt,\n",
    "                callbacks=[WandbTracer()]\n",
    "            )\n",
    "\n",
    "            print(f\"Prompt {i+1} of {len(prompts_list)}\")\n",
    "\n",
    "            output += \"\\n\\n\"\n",
    "\n",
    "        # if not os.path.exists(f\"../generated_prds/{product_name}\"):\n",
    "        #     os.makedirs(f\"../generated_prds/{product_name}\")\n",
    "\n",
    "        # with open(f\"../generated_prds/{product_name}/{product_name} 2023 Chat gpt-4.md\", \"w\") as f:\n",
    "        #     f.write(output)\n",
    "    \n",
    "    wandb.log({\"prd\": output})\n",
    "    clear_output()\n",
    "\n",
    "print(f\"Product name: {product_name}\")\n",
    "print(f\"Total tokens used: {callback.total_tokens}\")\n",
    "print(f\"Prompt Tokens: {callback.prompt_tokens}\")    \n",
    "print(f\"Completion Tokens: {callback.completion_tokens}\")\n",
    "print(f\"Successful Requests: {callback.successful_requests}\")\n",
    "print(f\"Total cost to generate: ${callback.total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_embed(search_query, vectordb):\n",
    "    search = GoogleSearch({\n",
    "    \"q\": search_query,\n",
    "    \"location\": \"Mumbai, Maharashtra, India\",\n",
    "    \"api_key\": os.environ[\"SERPAPI_API_KEY\"],\n",
    "    })\n",
    "\n",
    "    results = search.get_dict()\n",
    "\n",
    "    if \"error\" in results:\n",
    "        return f\"Error: {results['error']}\"\n",
    "            \n",
    "    else:\n",
    "        print(f\"Number of organic results: {len(results['organic_results'])}\")\n",
    "\n",
    "    results_condensed = [(result['title'], result['link']) for result in results['organic_results'][:3]]\n",
    "    content_p = \"\"\n",
    "    count_p = 0\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "    for title, link in results_condensed:\n",
    "        print(f\"Title: {title}\")\n",
    "        # print(f\"Link: {link}\")\n",
    "\n",
    "        try:\n",
    "            response = requests.get(link)\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(\"Connection timed out... Moving to next link\")\n",
    "            continue\n",
    "        # print(f\"Response code: {response.status_code}\")\n",
    "        # print(f\"Reponse Message: {http_responses[response.status_code]}\")\n",
    "        if response.status_code != 200:\n",
    "            print()\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        webpage = \"\"\n",
    "        webpage += f'## {title}' + \"\\n\"\n",
    "\n",
    "        content_p += f'## {title}' + \"\\n\"\n",
    "        for p in soup.find_all('p'):\n",
    "            paragraph = p.get_text(separator=' ')\n",
    "\n",
    "            if len(paragraph) > 100:\n",
    "                webpage += paragraph\n",
    "                content_p += paragraph\n",
    "                content_p += \"\\n\\n\"\n",
    "                count_p += 1\n",
    "\n",
    "        doc = text_splitter.create_documents(texts=[content_p], metadatas=[{\"source\": link, \"title\": title}])\n",
    "        ids = vectordb.add_documents(documents=[*doc])\n",
    "        print(f\"Added {len(ids)} documents to the database\")\n",
    "        print()\n",
    "\n",
    "        content_p += \"\\n-------------------------------------------------------------------------------------\\n\"\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    return \"Success\"\n",
    "\n",
    "def update_qa_chain(vectordb):\n",
    "    retriever = vectordb.as_retriever()\n",
    "\n",
    "    qa_chain_chat = ConversationalRetrievalChain.from_llm(llm=ChatOpenAI(model=\"gpt-4\"),\n",
    "                                                        chain_type=\"stuff\",\n",
    "                                                        retriever=retriever,\n",
    "                                                        return_source_documents=True,\n",
    "                                                        )\n",
    "    \n",
    "    return qa_chain_chat\n",
    "\n",
    "def search_competitors_info(competitors, competitor_queries, vectordb):\n",
    "    for competitor in competitors:\n",
    "        print(competitor)\n",
    "        for query in competitor_queries:\n",
    "            query = query.format(competitor=competitor)\n",
    "            search_and_embed(search_query=query, vectordb=vectordb)\n",
    "\n",
    "    return \"Success\"\n",
    "\n",
    "def query_competitors_db(competitors, qa_chain_chat):\n",
    "    comp_analysis_results = {competitor: {} for competitor in competitors}\n",
    "\n",
    "    for competitor in competitors:\n",
    "        print(f\"Competitor: {competitor}\")\n",
    "\n",
    "        competitor_queries = [\n",
    "        \"What is the user base of {competitor}?\",\n",
    "        \"What is the revenue of {competitor}?\",\n",
    "        \"What are new features of {competitor}?\",\n",
    "        ]\n",
    "\n",
    "        for query in competitor_queries:\n",
    "            db_res = qa_chain_chat(\n",
    "                {\n",
    "                    \"question\": query.format(competitor=competitor),\n",
    "                    \"chat_history\": [],\n",
    "                }\n",
    "            )\n",
    "            comp_analysis_results[competitor][query.format(competitor=competitor)] = db_res[\"answer\"]\n",
    "\n",
    "    return comp_analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goolge Search query: best dating apps\n"
     ]
    }
   ],
   "source": [
    "today = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "get_google_search_query_prompt = f\"\"\"Your training cutoff date is September 2021 while today is {today}.\n",
    "Generate a Google search query to find the names of competitor apps\n",
    "Only return the Google search query without the follwing things:\n",
    "- Double quotes\n",
    "- Current Year\n",
    "- A period at the end of the sentence\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with get_openai_callback() as google_search_query_callback:\n",
    "    search_query = chain.predict(\n",
    "        input=get_google_search_query_prompt,\n",
    "        callbacks=[WandbTracer()]\n",
    "    )\n",
    "\n",
    "print(f\"Goolge Search query: {search_query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve_apps_from_db_prompt = \"\"\"\\\n",
    "# The competition apps are stored in a vector database.\n",
    "# The vector database understands natural language, conversational based queries.\n",
    "# Generate a query to retrieve the names of competitor apps.\n",
    "# Only return the query without double quotes and period and include nothing else.\n",
    "# Do not specify the current date in the query.\n",
    "# \"\"\"\n",
    "\n",
    "# retrieve_apps_from_db_query = chain.predict(input=retrieve_apps_from_db_prompt)\n",
    "# print(retrieve_apps_from_db_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eHarmony\n",
      "Zoosk\n",
      "Finished embedding competitor information into VectorDB.\n",
      "Competitor: Tinder\n",
      "Competitor: Bumble\n",
      "Competitor: OkCupid\n",
      "Competitor: Hinge\n",
      "Competitor: CoffeeMeetsBagel\n",
      "Competitor: Happn\n",
      "Competitor: PlentyofFish\n",
      "Competitor: Match.com\n",
      "Competitor: eHarmony\n",
      "Competitor: Zoosk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished retrieving competitor information from VectorDB and parsed the results into a dictionary.\n"
     ]
    }
   ],
   "source": [
    "# search_query = \"What are the top dating apps in the market?\"\n",
    "vectordb = Chroma(embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "# 1. Search for competitors and embed them into VectorDB\n",
    "search_and_embed(search_query=search_query, vectordb=vectordb)\n",
    "print(\"Finished embedding list of competitors into VectorDB.\")\n",
    "\n",
    "# 2. Load the QA Chain\n",
    "qa_chain_chat = update_qa_chain(vectordb=vectordb)\n",
    "\n",
    "# 3. Retrieve the list of competitors from VectorDB\n",
    "competitors = qa_chain_chat(\n",
    "        {\n",
    "            \"question\": f\"{search_query}. Only return the names of the competitors in a comma separated list.\",\n",
    "            \"chat_history\": []\n",
    "        }\n",
    "    )['answer'].replace(\" \", \"\").split(\",\")\n",
    "\n",
    "print(\"Finished retrieving list of competitors from VectorDB:\")\n",
    "print(competitors)\n",
    "\n",
    "# 4. List the queries to search for competitor information\n",
    "competitor_queries = [\n",
    "        \"What is the user base of the {competitor}?\",\n",
    "        \"What is the revenue of the {competitor}?\",\n",
    "        \"What are new features of the {competitor}?\",\n",
    "    ]\n",
    "\n",
    "# 5. Search for competitor information on the web and embed them into VectorDB\n",
    "search_competitors_info(competitors=competitors, competitor_queries=competitor_queries, vectordb=vectordb)\n",
    "print(\"Finished embedding competitor information into VectorDB.\")\n",
    "\n",
    "# 6. Update the QA Chain\n",
    "qa_chain_chat = update_qa_chain(vectordb=vectordb)\n",
    "\n",
    "# 7. Retrieve the competitor information from VectorDB\n",
    "competitive_analysis_results = query_competitors_db(competitors=competitors, qa_chain_chat=qa_chain_chat)\n",
    "print(\"Finished retrieving competitor information from VectorDB and parsed the results into a dictionary.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: Rate limit reached for 10KTPM-200RPM in organization org-sRS5hauWsP4QYcQcLLz6SCCw on tokens per min. Limit: 10000 / min. Please try again in 6ms. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>prd</td><td># DateSmart Product ...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">DateSmart_gpt-4</strong> at: <a href='https://wandb.ai/arihantsheth/chat-prd-gpt-4/runs/g163pt7t' target=\"_blank\">https://wandb.ai/arihantsheth/chat-prd-gpt-4/runs/g163pt7t</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230731_172629-g163pt7t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "market_analysis_prompt = f\"\"\"\\\n",
    "The following nested JSON formatted object contains details of competitor apps. Use this information to support your analysis of the market and the product if required:\n",
    "{competitive_analysis_results}\n",
    "\n",
    "Now, let us get continue generating the PRD using the same Markdown format as before.\n",
    "\n",
    "Market Analysis:\n",
    "Include major or minor differences between our product and the competitor products. \\\n",
    "Analyze how aspects of our product or competitor products are better for that particular aspect. \\\n",
    "How do the target customers different? \\\n",
    "Does our product better cater to current trends and expectations of the users? How? \\\n",
    "What should the product include to meet those trends and expectations.\n",
    "\"\"\"\n",
    "\n",
    "competitive_table_prompt = \"\"\"\\\n",
    "Competitive Analysis:\n",
    "Use all the above competitors to create a competitive analysis of these applications in a tabular form using the following points - user base, user region, different features supported, and pricing tiers. \\\n",
    "Don't limit yourself to these categories and think of other categories yourself. \n",
    "Return the output in a well-structured Markdown table. Use the competitor app details from the JSON object if required.\n",
    "\"\"\"\n",
    "\n",
    "final_prompt = \"\"\"\\\n",
    "Conclusion:\n",
    "Include any final thoughts or comments about the product or the market. \\\n",
    "Include any other information that you think is important to get across to the reader. \\\n",
    "Include any information that is not present in the PRD but is important to the product.\n",
    "\"\"\"\n",
    "\n",
    "with get_openai_callback() as callback_market_analysis:\n",
    "    market_analysis_output = chain.predict(\n",
    "        input=market_analysis_prompt,\n",
    "        callbacks=[WandbTracer()]\n",
    "    )\n",
    "\n",
    "    output += market_analysis_output + \"\\n\\n\"\n",
    "\n",
    "    competitive_table_output = chain.predict(\n",
    "        input=competitive_table_prompt,\n",
    "        callbacks=[WandbTracer()]\n",
    "    )\n",
    "\n",
    "    output += competitive_table_output + \"\\n\\n\"\n",
    "\n",
    "    final_output = chain.predict(\n",
    "        input=final_prompt,\n",
    "        callbacks=[WandbTracer()]\n",
    "    )\n",
    "\n",
    "    output += final_output + \"\\n\\n\"\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product name: DateSmart\n",
      "Total tokens used: 53218\n",
      "Prompt Tokens: 48402\n",
      "Completion Tokens: 4816\n",
      "Successful Requests: 14\n",
      "Total cost to generate: $1.74\n"
     ]
    }
   ],
   "source": [
    "total_tokens = callback.total_tokens + google_search_query_callback.total_tokens + callback_market_analysis.total_tokens\n",
    "prompt_tokens = callback.prompt_tokens + google_search_query_callback.prompt_tokens + callback_market_analysis.prompt_tokens\n",
    "completion_tokens = callback.completion_tokens + google_search_query_callback.completion_tokens + callback_market_analysis.completion_tokens\n",
    "successful_requests = callback.successful_requests + google_search_query_callback.successful_requests + callback_market_analysis.successful_requests\n",
    "total_cost = callback.total_cost + google_search_query_callback.total_cost + callback_market_analysis.total_cost\n",
    "\n",
    "print(f\"Product name: {product_name}\")\n",
    "print(f\"Total tokens used: {total_tokens}\")\n",
    "print(f\"Prompt Tokens: {prompt_tokens}\")    \n",
    "print(f\"Completion Tokens: {completion_tokens}\")\n",
    "print(f\"Successful Requests: {successful_requests}\")\n",
    "print(f\"Total cost to generate: ${total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     \"\"\"Market Research:\n",
    "# First, list out current and potential competitors. Current competitors should include already established businesses/products. Potential competitors should include products and businesses that aren’t yet popular or are still under development/ beta version. Also include major or minor differences between our product and the competitor products you have identified. Analyze how aspects of our product or competitor products are better for that particular aspect. How do the target customers different? Does our product better cater to current trends and expectations of the users? How? What should the product include to meet those trends and expectations.\"\"\",\n",
    "#     \"\"\"Competitive Analysis Table:\n",
    "# Use all the above competitors to create a competitive analysis of these applications in a tabular form using the following points - user base, user region, different features supported, and pricing tiers. Don't limit yourself to these categories and think of other categories yourself. Return the output in a well-structured Markdown table\"\"\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"../generated_prds/{product_name}\"):\n",
    "    os.makedirs(f\"../generated_prds/{product_name}\")\n",
    "\n",
    "with open(f\"../generated_prds/{product_name}/{product_name} with internet Chat gpt-4.md\", \"w\") as f:\n",
    "    f.write(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synap_labs_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
